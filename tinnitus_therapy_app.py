import streamlit as st

# âœ… ë°˜ë“œì‹œ ìµœìƒë‹¨ì— ìœ„ì¹˜í•´ì•¼ í•¨!
st.set_page_config(page_title="Tinnitus Therapy", layout="centered")

import pandas as pd
import datetime
import os
import csv
import json
from pydub import AudioSegment
import numpy as np
import scipy.signal

# ğŸ”½ step ìƒíƒœ ì´ˆê¸°í™”
if "step" not in st.session_state:
    st.session_state.step = 0

# ë¡œê·¸ì¸ ê¸°ëŠ¥
user_file = "user_credentials.csv"
if not os.path.exists(user_file):
    with open(user_file, mode="w", newline="") as f:
        writer = csv.writer(f)
        writer.writerow(["email", "password"])

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ” ê³„ì •ì´ ì—†ìœ¼ì‹ ê°€ìš”?")
new_email = st.sidebar.text_input("ì‹ ê·œ ì´ë©”ì¼", key="reg_email")
new_pw = st.sidebar.text_input("ì‹ ê·œ ë¹„ë°€ë²ˆí˜¸", type="password", key="reg_pw")
if st.sidebar.button("íšŒì›ê°€ì…"):
    with open(user_file, mode="a", newline="") as f:
        writer = csv.writer(f)
        writer.writerow([new_email, new_pw])
    st.sidebar.success("íšŒì›ê°€ì… ì™„ë£Œ. ë¡œê·¸ì¸ í•´ì£¼ì„¸ìš”!")

if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

if not st.session_state.authenticated:
    st.title("ğŸ” ë¡œê·¸ì¸")
    email = st.text_input("ì´ë©”ì¼ì„ ì…ë ¥í•˜ì„¸ìš”")
    password = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")

    if st.button("ë¡œê·¸ì¸"):
        with open(user_file, newline="") as f:
            reader = csv.DictReader(f)
            for row in reader:
                if row["email"] == email and row["password"] == password:
                    st.session_state.authenticated = True
                    st.session_state.user_email = email
                    st.success(f"{email} ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤!")
                    st.rerun()
    if not st.session_state.authenticated:
        st.error("ì´ë©”ì¼ ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()

st.title("ğŸµ ìŒì•…ìœ¼ë¡œ ì´ëª… ì¹˜ë£Œí•˜ë‹¤")
st.markdown("## ğŸ§ Tinnitus Sound Therapy App")
st.markdown("<style> @keyframes fadein { from {opacity:0;} to {opacity:1;} } .slide { animation: fadein 1s ease-in-out; } </style>", unsafe_allow_html=True)

# ğŸ”§ ì„¸ì…˜ ë³€ìˆ˜ ì´ˆê¸°í™”
for var, default in {
    "mode": None,
    "tinnitus_level": 5,
    "audio_file": None,
    "user_info": {},
    "health_info": {},
    "thi_results": {},
    "treatment_history": [],
    "feedback_log": {},
    "thi_score": 0,
    "matching_info": {},
    "filter_type": "Amplitude Modulation"
}.items():
    if var not in st.session_state:
        st.session_state[var] = default

# ğŸ›ï¸ í•„í„° í•¨ìˆ˜ ì •ì˜

def apply_notch_filter(input_path, output_path, freq=1000, q=30):
    sound = AudioSegment.from_file(input_path)
    samples = np.array(sound.get_array_of_samples())
    fs = sound.frame_rate
    b, a = scipy.signal.iirnotch(freq / (fs / 2), q)
    filtered = scipy.signal.filtfilt(b, a, samples).astype(np.int16)
    filtered_audio = sound._spawn(filtered.tobytes())
    filtered_audio.export(output_path, format="wav")

def apply_amplitude_modulation(input_path, output_path, rate=5):
    sound = AudioSegment.from_file(input_path)
    samples = np.array(sound.get_array_of_samples())
    fs = sound.frame_rate
    duration = len(samples) / fs
    t = np.linspace(0, duration, num=len(samples))
    modulator = 0.5 * (1 + np.sin(2 * np.pi * rate * t))
    modulated = samples * modulator
    modulated = np.clip(modulated, -2**15, 2**15-1)
    modulated_audio = sound._spawn(modulated.astype(np.int16).tobytes())
    modulated_audio.export(output_path, format="wav")

# ğŸ”„ Pitch ì£¼íŒŒìˆ˜ ë§µ
pitch_freq_map = {
    "125Hz": 125,
    "250Hz": 250,
    "500Hz": 500,
    "1kHz": 1000,
    "2kHz": 2000,
    "4kHz": 4000,
    "8kHz": 8000
}

# ğŸ” ì¹˜ë£Œ ê¸°ëŠ¥
if st.session_state.step == 4:
    st.header("ğŸ§ [ì¹˜ë£Œ ê¸°ëŠ¥] ë§ì¶¤í˜• ìŒì› ì¹˜ë£Œ")
    st.markdown("""
Pitch ë° Loudness ì¸¡ì • ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ
ë§ì¶¤í˜• ì‚¬ìš´ë“œê°€ ì ìš©ë©ë‹ˆë‹¤. ê³¨ì „ë„ ë˜ëŠ” ì¼ë°˜ ì´ì–´í°ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
""")

    st.subheader("ğŸµ ìŒì› ì„ íƒ")
    uploaded = st.file_uploader("ğŸ¶ ì¢‹ì•„í•˜ëŠ” ìŒì•… ì—…ë¡œë“œ (mp3, wav)", type=["mp3", "wav"])
    if uploaded is not None:
        path = f"uploaded_{uploaded.name}"
        with open(path, "wb") as f:
            f.write(uploaded.read())
        st.session_state.audio_file = path
        st.audio(path)

    if st.session_state.audio_file:
        st.subheader("âš™ï¸ Modulation ì„¤ì •")
        st.session_state.filter_type = st.radio("í•„í„° íƒ€ì… ì„ íƒ", ["Amplitude Modulation", "Notch Filtering"])
        mod_rate = st.slider("Modulation Rate (Hz)", 1, 20, 5)
        q_value = st.slider("Notch Filter Q ê°’", 5, 100, 30)
        duration = st.slider("ì¹˜ë£Œ ì‹œê°„ (ë¶„)", 5, 60, 15)

        output_path = "modulated_audio.wav"
        intermediate_path = "notch_filtered.wav"

        pitch = st.session_state.matching_info.get("Pitch", "1kHz")
        notch_freq = pitch_freq_map.get(pitch, 1000)

        if st.button("ì¹˜ë£Œ ì‹œì‘"):
            if st.session_state.filter_type == "Notch Filtering":
                apply_notch_filter(st.session_state.audio_file, intermediate_path, freq=notch_freq, q=q_value)
                apply_amplitude_modulation(intermediate_path, output_path, rate=mod_rate)
            else:
                apply_amplitude_modulation(st.session_state.audio_file, output_path, rate=mod_rate)

            st.audio(output_path)
            st.success(f"{duration}ë¶„ ì¹˜ë£Œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. ìŒì›: {st.session_state.audio_file}")

